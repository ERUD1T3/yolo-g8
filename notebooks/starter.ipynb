{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Learning MTH 5320 \n",
    "## Homework 3\n",
    "## 12/1/2023\n",
    "## By Josias Moukpe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ba81126aaed913f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Object Detection Model Assignment\n",
    "\n",
    "### Dataset Prep and Preprocessing (20 points)\n",
    "- Collect or create a dataset of images containing the objects you want to detect annotated with bounding boxes.\n",
    "- Implement data preprocessing techniques, including:\n",
    "  - Resizing images\n",
    "  - Normalizing pixels\n",
    "- Hint: You can find pre-annotated datasets for download on [Roboflow](https://github.com/roboflow/supervision).\n",
    "\n",
    "### Model Architecture (30 points)\n",
    "- Train a YOLOv8 model on your selected dataset using the public repository available at [Ultralytics](https://github.com/ultralytics/ultralytics).\n",
    "- Monitor the training progress and use appropriate techniques to prevent overfitting.\n",
    "- Conduct at least 3 tuning experiments.\n",
    "\n",
    "### Evaluation (20 points)\n",
    "- Evaluate your trained model's performance on a test dataset using mAP (mean Average Precision).\n",
    "- Visualize the model's predictions on sample images.\n",
    "- Analyze the model's performance, discussing any specific failure modes on your test dataset.\n",
    "\n",
    "### BONUS (25 bonus points)\n",
    "- Design and train a custom CNN-based object detection model using a self-designed architecture.\n",
    "- Alternatively, compare several publicly available models on the same dataset.\n",
    "- Consider implementing Gaussian YOLO V8 and comparing it against YOLO V8.\n",
    "\n",
    "Please ensure that your code includes docstrings and type hints as requested, and be thorough in your analysis and experimentation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5b0040c7ba5685e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup and Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff2fced5a3fdcef8"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-06T05:11:40.513815500Z",
     "start_time": "2023-12-06T05:11:37.031657200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} device')\n",
    "# get device specs\n",
    "print(torch.cuda.get_device_name(0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T05:12:30.554289400Z",
     "start_time": "2023-12-06T05:12:30.442303100Z"
    }
   },
   "id": "ebbae101c1442e47"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# test of yolo  v8\n",
    "model = YOLO('yolov8n.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T05:12:32.898585Z",
     "start_time": "2023-12-06T05:12:32.762094Z"
    }
   },
   "id": "2244d1d3cd0b39af"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# vid_path = \"../data/test_footage.mp4\"\n",
    "# results = model(source=vid_path, show=True, conf=0.4, save=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T05:12:33.904520Z",
     "start_time": "2023-12-06T05:12:33.860536100Z"
    }
   },
   "id": "423ea9aa1b17b39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "debc7d0f0e631a0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ocr_dataset_path = 'D:/College/Fall2023/DeepLearning/yolo_ocr'\n",
    "yaml_path = 'D:/College/Fall2023/DeepLearning/yolo_ocr/data.yaml'\n",
    "# labels already in yolo v8 format"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T05:12:36.297729600Z",
     "start_time": "2023-12-06T05:12:36.245740900Z"
    }
   },
   "id": "3e86c5b75e21151"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.222 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.221 🚀 Python-3.9.18 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0mtask=detect, mode=train, model=yolov8n.pt, data=D:/College/Fall2023/DeepLearning/yolo_ocr/data.yaml, epochs=10, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolov8n_ocr2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\yolov8n_ocr2\n",
      "Overriding model.yaml nc=80 with nc=36\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    758332  ultralytics.nn.modules.head.Detect           [36, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3017868 parameters, 3017852 gradients, 8.2 GFLOPs\n",
      "Transferred 319/355 items from pretrained weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33merud1t3\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\the_3\\OneDrive\\Desktop\\school\\Fall 2023\\yolo-g8\\notebooks\\wandb\\run-20231206_001258-z8uow0e5</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/erud1t3/YOLOv8/runs/z8uow0e5' target=\"_blank\">yolov8n_ocr2</a></strong> to <a href='https://wandb.ai/erud1t3/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/erud1t3/YOLOv8' target=\"_blank\">https://wandb.ai/erud1t3/YOLOv8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/erud1t3/YOLOv8/runs/z8uow0e5' target=\"_blank\">https://wandb.ai/erud1t3/YOLOv8/runs/z8uow0e5</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\train\\labels.cache... 4245 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4245/4245 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\train\\images\\03c3dfc7e998b8562_jpg.rf.3d9d76c2437bcfb5cf433c0b6306d1ac.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\train\\images\\185d5dfa193c4ced_jpg.rf.b3d2ab34086b9e8f050b514cc22b4b9a.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\train\\images\\24c1fc0bf63da8153_jpg.rf.bd40f6e750b1a7990a9945aadddc1ef1.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\train\\images\\421ca0ce7f9329622_jpg.rf.4e25470bde67152fea6834e88e803708.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\train\\images\\4572990fd64bb6be3_jpg.rf.7ce23d5cd8b919a7832485c4815d97c8.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\train\\images\\492f6d607aae58c12_jpg.rf.44d8f6885cd8664eeff661809ad807ab.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\train\\images\\624860d2c1d529cf3_jpg.rf.0e1b82945bb5fb1b4402a8a8039f45b4.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\train\\images\\6520279c853247d5_jpg.rf.79ecc5c23c55675d0e25a1b5e0b07a9a.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\train\\images\\66144e8ccb6114bc_jpg.rf.a5bd76659353fe5df4d9ca50d0d2a727.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\train\\images\\73bba7d7f439b76f_jpg.rf.59cfcd935931741505777badc23b52ae.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\train\\images\\86063e808f33e6a5_jpg.rf.fed978bb4e241d36376321e03a32df55.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\train\\images\\d3de1c42196d3b3e2_jpg.rf.c9b4b5a50d4bc11c338c33ddf29f56c1.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\train\\images\\e8a1a9c789e6ee6e_jpg.rf.c434c9ae469eb57e14fdd5cee9c8a135.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\valid\\labels.cache... 1221 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1221/1221 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\valid\\images\\0ecee0dd32848030_jpg.rf.ffe2fb185ba29646fcf16eacf0e99021.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mval: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\valid\\images\\22deb87614a920e6_jpg.rf.a72d572c1920415b880c030e7b1a17e6.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mval: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\valid\\images\\dcb210b4cae8edf22_jpg.rf.286248320e4fe0f26c75339865578ccc.jpg: 1 duplicate labels removed\n",
      "\u001B[34m\u001B[1mval: \u001B[0mWARNING ⚠️ D:\\College\\Fall2023\\DeepLearning\\yolo_ocr\\valid\\images\\f7f068d4fb49a4f34_jpg.rf.8856a3518481e9dcc022b1a802a966cd.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\yolov8n_ocr2\\labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.00025, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001B[1mruns\\detect\\yolov8n_ocr2\u001B[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n"
     ]
    }
   ],
   "source": [
    "# Training.\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    imgsz=640,\n",
    "    epochs=10,\n",
    "    batch=8,\n",
    "    name='yolov8n_ocr')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-06T05:12:51.729769700Z"
    }
   },
   "id": "d1ce912d2edf32eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85b3555bc208874"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "59dccdb1e2ca7d4d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Custom Yolo G8 Architecture in Pytorch (NO UltraLytics here unfortunately)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "514485cf9c563ab1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
